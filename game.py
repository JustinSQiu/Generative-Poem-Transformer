import pandas as pd
from openai import OpenAI
import os
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
import random
from embedding_comparison import load_embeddings, compare

if 'HELICONE_API_KEY' not in os.environ:
    print("You didn't set your Helicone key to the HELICONE_API_KEY env var on the command line.")
    os.environ['HELICONE_API_KEY'] = input("Please input the helicone api key:")

client = OpenAI(base_url="https://oai.hconeai.com/v1", api_key=os.environ['HELICONE_API_KEY'])
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

easy_df = pd.read_csv("data/easy_poems.csv")
medium_df = pd.read_csv("data/medium_poems.csv")
hard_df = pd.read_csv("data/hard_poems.csv")

attributes = ['formal', 'traditional', 'serious', 'romantic', 'rhythmic', 'intense', 'emotional',  'profound', 'expressive', 'happy']

# Choose a random poem from the dataframe
def select_random_poem(poem_df):
  random_index = random.randint(0, len(poem_df) - 1)
  random_poem = poem_df.iloc[random_index].to_dict()
  return (random_poem['Poem Prompt'], random_poem['Poem'], random_poem['Topic'], random_poem['Style'], random_poem['Structure'])

# difficulty: 0 = easy, 1 = medium, 2 = hard
def create_poem_from_prompt(prompt, difficulty):
  extra_prompt = ""
  freq_penalty = 0
  temp = 0.5
  if difficulty == 2:
     extra_prompt = " Do not mention the topic of the poem explicity."
     freq_penalty = 0.5
     temp = 1
  elif difficulty == 1:
     extra_prompt = " Talk about the topic of the poem less obviously."
     freq_penalty = 0.7
     temp = 1.5
  messages = [
      {'role': 'system', 'content': prompt + ". Limit the poem to be 40 words." + extra_prompt}
  ]

  response = client.chat.completions.create(
      model='gpt-4',
      messages=messages,
      temperature=temp,
      max_tokens=2048,
      top_p=1.0,
      frequency_penalty=freq_penalty,
      presence_penalty=0
  )
  gpt_response = response.choices[0].message.content
  return gpt_response

# Compute cosine similarity between two prompts
def compute_similarity(prompt1, prompt2):
  prompt1_embedding = model.encode(prompt1)
  prompt2_embedding = model.encode(prompt2)
  similarity = cosine_similarity([prompt1_embedding], [prompt2_embedding])[0][0]
  # scale the cosine similarity to be between 0 and 1
  similarity = (similarity + 1) / 2
  return similarity

# Generate gpt feedback for how to make the user's prompt more similar to the original prompt 
# so that the generated poem is more similar to the original generated poem
def generate_feedback(user_prompt, orig_poem, orig_prompt):
    system_prompt = f'''
    You are an assistant in a system where the user is given a gpt-4 generated poem and needs to guess what the original prompt is.
    Given the original prompt, the poem generated by the original prompt, and the user's prompt, provide brief feedback on how the user's prompt can be improved. Don't mention the original prompt in the feedback.
    '''
    user_prompt = f'''
    The original prompt is "{orig_prompt}", the poem generated by the original prompt is "{orig_poem}". The user's prompt is "{user_prompt}".
    '''
    messages=[
        {
            "role": "system",
            "content": system_prompt
        },
        {
            "role": "user",
            "content": user_prompt
        }
    ]
    
    response = client.chat.completions.create(
        model='gpt-4',
        messages=messages,
        temperature=1,
        max_tokens=2048,
        top_p=1.0,
        frequency_penalty=0,
        presence_penalty=0
    )
    gpt_response = response.choices[0].message.content
    return gpt_response

def llm_output_match(prompt, phrase):
  prompt = f'Does the following input mention the attribute {phrase}?\nPrompt: {prompt}. Respond with only "yes" or "no"'
  messages = [
      {'role': 'system', 'content': prompt}
  ]
  response = client.chat.completions.create(
      model='gpt-4',
      messages=messages,
      temperature=1,
      max_tokens=2048,
      top_p=1.0,
      frequency_penalty=0,
      presence_penalty=0
  )
  gpt_response = response.choices[0].message.content
  return gpt_response

def give_feedback(user_poem, user_prompt, orig_poem_topic, orig_poem_style, orig_poem_structure):
  topic_similarity = llm_output_match(user_prompt, orig_poem_topic)
  print(f"Matched topic: {topic_similarity}")
  style_similarity = llm_output_match(user_prompt, orig_poem_style)
  print(f"Matched style: {style_similarity}")
  structure_similarity = llm_output_match(user_prompt, orig_poem_structure)
  print(f"Matched structure: {structure_similarity}")

def generate_mcq(orig_poem, orig_poem_xxx, xxx):
  prompt = f'Generate a multiple-choice question about the {xxx} of the following {orig_poem_xxx} poem: {orig_poem}. Respond should be a multiple-choice question in the format "What {xxx} of poetry is represented in the poem?" with 3 options, including {orig_poem_xxx} as one of the answer options. Include a definition in each option, but do not give away the answer'
  messages = [
      {'role': 'system', 'content': prompt}
  ]
  response = client.chat.completions.create(
      model='gpt-4',
      messages=messages,
      temperature=1,
      max_tokens=2048,
      top_p=1.0,
      frequency_penalty=0,
      presence_penalty=0
  )
  gpt_response = response.choices[0].message.content
  return gpt_response

def generate_hints(orig_poem, orig_poem_topic, orig_poem_style, orig_poem_structure):
    hints = []
    hints.append(generate_mcq(orig_poem, orig_poem_topic, "topic"))
    hints.append(generate_mcq(orig_poem, orig_poem_style, "style"))
    hints.append(generate_mcq(orig_poem, orig_poem_structure, "structure"))
    return hints

# Compute the attribute that the user's poem is most different from the original poem
# diff is the number of attributes that the user's poem is different from the original poem (greater than threshold)
# diff_attribute is the most different attribute (out of 10)
def compute_attribute_similarity(orig_poem, user_poem):    
    orig_poem_similarity_scores = compare(orig_poem)
    user_poem_similarity_scores = compare(user_poem)
    diff = 0
    max_diff, max_diff_idx = 0, 0
    for i in range(len(orig_poem_similarity_scores)):
        print(abs(orig_poem_similarity_scores[i] - user_poem_similarity_scores[i]))
        diff += 1 if abs(orig_poem_similarity_scores[i] - user_poem_similarity_scores[i]) > 0.03 else 0
        if abs(orig_poem_similarity_scores[i] - user_poem_similarity_scores[i]) > max_diff:
            max_diff = abs(orig_poem_similarity_scores[i] - user_poem_similarity_scores[i])
            max_diff_idx = i
    return diff, attributes[max_diff_idx]

# Generate similarity score and feedback
def compute_final_similarity_and_feedback(user_poem, user_input, orig_poem_topic, orig_poem_style, orig_poem_structure, orig_poem, orig_prompt):
    topic_similarity = llm_output_match(user_input, orig_poem_topic)
    print(f"Matched topic: {topic_similarity}")
    style_similarity = llm_output_match(user_input, orig_poem_style)
    print(f"Matched style: {style_similarity}")
    structure_similarity = llm_output_match(user_input, orig_poem_structure)
    print(f"Matched structure: {structure_similarity}")
    diff, diff_attribute = compute_attribute_similarity(user_poem, orig_poem)

    prompt_sim = compute_similarity(user_input, orig_prompt)
    poem_sim = compute_similarity(user_poem, orig_poem)
    
    # COMPUTE SCORE
    # 3 + 20 + 10 * 3 + 10 = 100
    score = prompt_sim * 30 + poem_sim * 45 + ((1 if topic_similarity.lower() == "yes" else 0) + (1 if style_similarity.lower() == "yes" else 0) + (1 if structure_similarity.lower() == "yes" else 0)) * 5 + (10 - diff)

    # Toggles for giving mc hints
    structure_hint = False
    style_hint = False
    topic_hint = False

    missed_attributes = []
    hint_mcqs = []

    if topic_similarity.lower() == "no":
        missed_attributes.append("topic")
        if topic_hint:
            hint_mcqs.append(generate_mcq(orig_poem, orig_poem_topic, "topic"))
    if style_similarity.lower() == "no":
        missed_attributes.append("style")
        if style_hint:
            hint_mcqs.append(generate_mcq(orig_poem, orig_poem_style, "style"))
    if structure_similarity.lower() == "no":
        missed_attributes.append("structure")
        if structure_hint:
            hint_mcqs.append(generate_mcq(orig_poem, orig_poem_structure, "structure"))

    missed_attributes_str = ""
    if len(missed_attributes) == 0:
        missed_attributes_str = ''
    elif len(missed_attributes) == 1:
        missed_attributes_str = str(missed_attributes[0])
    else:
        all_but_last = ', '.join(map(str, missed_attributes[:-1]))
        missed_attributes_str = f"{all_but_last}, and {missed_attributes[-1]}"

    missed_true_attribute = ""
    hints = '\n'.join(hint_mcqs)
    if len(missed_attributes) > 0:
        missed_true_attribute = f"You got the {missed_attributes_str} wrong. {hints}\n"

    reaction = ""
    if score > 90:
        reaction = f"That's amazing!"
    elif score > 70:
        reaction = f"Great job!"
    elif score > 50:
        reaction = f"Nice try!"
    else:
        reaction = f"Keep trying!"

    gpt_feedback = generate_feedback(user_input, orig_poem, orig_prompt)
    feedback = f'''
    {reaction} {gpt_feedback} Also, try to make your prompt closer the attribute {diff_attribute}!\n
    '''
    return score, feedback

def main():
    load_embeddings()
    for difficulty in range(3):
        best_score = 0
        difficulty_str = "EASY" if difficulty == 0 else "MEDIUM" if difficulty == 1 else "HARD"
        print(f"DIFFICULTY: {difficulty_str}\n")
        if difficulty == 0:
            orig_prompt, orig_poem, orig_poem_topic, orig_poem_style, orig_poem_structure = select_random_poem(easy_df)
        elif difficulty == 1:
            orig_prompt, orig_poem, orig_poem_topic, orig_poem_style, orig_poem_structure = select_random_poem(medium_df)
        else:
            orig_prompt, orig_poem, orig_poem_topic, orig_poem_style, orig_poem_structure = select_random_poem(hard_df)
        print(f"ORIGINAL POEM\n{orig_poem}\n")
        for round in range(3):
            print(f"ROUND {round+1}")
            user_input = input("Guess the prompt for the poem: ")
            user_poem = create_poem_from_prompt(user_input, difficulty)
            print(f"USER POEM\n{user_poem}\n")

            poem_similarity, feedback = compute_final_similarity_and_feedback(user_poem, user_input, orig_poem_topic, orig_poem_style, orig_poem_structure, orig_poem, orig_prompt)
            print(f"SIMILARITY: {poem_similarity}")
            print(f"FEEDBACK: {feedback}")
            best_score = max(best_score, poem_similarity)

        print(f"BEST SCORE: {best_score}\n\n")
        print(f"The answer was: {orig_prompt}\n")

main()